{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "from mark_detector import MarkDetector\n",
    "from os_detector import detect_os\n",
    "from pose_estimator import PoseEstimator\n",
    "from stabilizer import Stabilizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux is fine! Python multiprocessing works.\n"
     ]
    }
   ],
   "source": [
    "# multiprocessing may not work on Windows and macOS, check OS for safety.\n",
    "detect_os()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_INPUT_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_face(detector, img_queue, box_queue):\n",
    "    \"\"\"Get face from image queue. This function is used for multiprocessing\"\"\"\n",
    "    while True:\n",
    "        image = img_queue.get()\n",
    "        box = detector.extract_cnn_facebox(image)\n",
    "        box_queue.put(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video source from webcam or video file.\n",
    "video_src = 'fbl3.mp4'\n",
    "cam = cv2.VideoCapture(video_src)\n",
    "_, sample_frame = cam.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce mark_detector to detect landmarks.\n",
    "mark_detector = MarkDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup process and queues for multiprocessing.\n",
    "img_queue = Queue()\n",
    "box_queue = Queue()\n",
    "img_queue.put(sample_frame)\n",
    "box_process = Process(target=get_face, args=(\n",
    "    mark_detector, img_queue, box_queue,))\n",
    "box_process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce pose estimator to solve pose. Get one frame to setup the\n",
    "# estimator according to the image size.\n",
    "height, width = sample_frame.shape[:2]\n",
    "pose_estimator = PoseEstimator(img_size=(height, width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce scalar stabilizers for pose.\n",
    "pose_stabilizers = [Stabilizer(\n",
    "    state_num=2,\n",
    "    measure_num=1,\n",
    "    cov_process=0.1,\n",
    "    cov_measure=0.1) for _ in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # Read frame, crop it, flip it, suits your needs.\n",
    "    frame_got, frame = cam.read()\n",
    "    if frame_got is False:\n",
    "        break\n",
    "\n",
    "    # Crop it if frame is larger than expected.\n",
    "    # frame = frame[0:480, 300:940]\n",
    "\n",
    "    # If frame comes from webcam, flip it so it looks like a mirror.\n",
    "    if video_src == 0:\n",
    "        frame = cv2.flip(frame, 2)\n",
    "\n",
    "    # Pose estimation by 3 steps:\n",
    "    # 1. detect face;\n",
    "    # 2. detect landmarks;\n",
    "    # 3. estimate pose\n",
    "\n",
    "    # Feed frame to image queue.\n",
    "    img_queue.put(frame)\n",
    "\n",
    "    # Get face from box queue.\n",
    "    facebox = box_queue.get()\n",
    "\n",
    "    if facebox is not None:\n",
    "        # Detect landmarks from image of 128x128.\n",
    "        face_img = frame[facebox[1]: facebox[3],\n",
    "                         facebox[0]: facebox[2]]\n",
    "        face_img = cv2.resize(face_img, (CNN_INPUT_SIZE, CNN_INPUT_SIZE))\n",
    "        face_img = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n",
    "        marks = mark_detector.detect_marks(face_img)\n",
    "\n",
    "        # Convert the marks locations from local CNN to global image.\n",
    "        marks *= (facebox[2] - facebox[0])\n",
    "        marks[:, 0] += facebox[0]\n",
    "        marks[:, 1] += facebox[1]\n",
    "\n",
    "        # Uncomment following line to show raw marks.\n",
    "        # mark_detector.draw_marks(\n",
    "        #     frame, marks, color=(0, 255, 0))\n",
    "\n",
    "        # Try pose estimation with 68 points.\n",
    "        pose = pose_estimator.solve_pose_by_68_points(marks)\n",
    "\n",
    "        # Stabilize the pose.\n",
    "        stabile_pose = []\n",
    "        pose_np = np.array(pose).flatten()\n",
    "        for value, ps_stb in zip(pose_np, pose_stabilizers):\n",
    "            ps_stb.update([value])\n",
    "            stabile_pose.append(ps_stb.state[0])\n",
    "        stabile_pose = np.reshape(stabile_pose, (-1, 3))\n",
    "\n",
    "        # Uncomment following line to draw pose annotaion on frame.\n",
    "        # pose_estimator.draw_annotation_box(\n",
    "        #     frame, pose[0], pose[1], color=(255, 128, 128))\n",
    "\n",
    "        # Uncomment following line to draw stabile pose annotaion on frame.\n",
    "        pose_estimator.draw_annotation_box(\n",
    "            frame, stabile_pose[0], stabile_pose[1], color=(128, 255, 128))\n",
    "\n",
    "    # Show preview.\n",
    "    cv2.imshow(\"Preview\", frame)\n",
    "    if cv2.waitKey(10) == 27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the multiprocessing process.\n",
    "box_process.terminate()\n",
    "box_process.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
